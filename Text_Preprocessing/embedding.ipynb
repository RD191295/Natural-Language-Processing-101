{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "\n",
    "#### One-hot encoding is a simple but effective technique in Natural Language Processing (NLP) for representing categorical data, such as words or characters, as numerical vectors. Here's how it works:\n",
    "\n",
    "#### One-hot encoding represents each word (or character) in a vocabulary as a binary vector where:\n",
    "\n",
    "#### <li> The vector length is equal to the size of the vocabulary. </li>\n",
    "#### <li> Only one position in the vector is set to 1 (hot), while all others are 0 (cold).</li>\n",
    "#### <li> The position of 1 is unique for each word.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corups = [\"i love nlp\",\"i teach gen ai\",\"i love data science\",\n",
    "          \"i am working with mitsubishi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'love',\n",
       " 'nlp',\n",
       " 'i',\n",
       " 'teach',\n",
       " 'gen',\n",
       " 'ai',\n",
       " 'i',\n",
       " 'love',\n",
       " 'data',\n",
       " 'science',\n",
       " 'i',\n",
       " 'am',\n",
       " 'working',\n",
       " 'with',\n",
       " 'mitsubishi']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = \" \".join(corups).split()\n",
    "vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = set(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {w:i for i,w in enumerate(vocab_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       " [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]],\n",
       " [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]],\n",
       " [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vector = []\n",
    "\n",
    "for sentence in corups:\n",
    "    #print(sentence)\n",
    "    sentence_vector = []\n",
    "\n",
    "    for word in sentence.split():\n",
    "        vector = [0] * len(vocab_set)\n",
    "        vector[word_to_index[word]] = 1\n",
    "        sentence_vector.append(vector)\n",
    "    \n",
    "    one_hot_vector.append(sentence_vector) \n",
    "    \n",
    "    #print(sentence)\n",
    "    #print(sentence_vector)\n",
    "one_hot_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words (BOW)\n",
    "\n",
    "#### Bag of Words (BoW) is a simple and widely used text representation technique in Natural Language Processing (NLP). It converts text into numerical feature vectors by counting the occurrences of words, ignoring grammar and word order but keeping track of word frequency.\n",
    "\n",
    "## Limitations\n",
    "#### <li>Ignores meaning: \"I love programming\" and \"Programming love I\" are treated the same.</li>\n",
    "#### <li>High dimensionality: If vocabulary is large, vectors become sparse.</li>\n",
    "#### <li>Does not capture semantics: Words like \"good\" and \"great\" are treated as independent.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0],\n",
       "       [3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 2, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "corups = [\"i i i love nlp nlp nlp\",\"i teach gen ai ai ai\",\"i love data science as data is new oil\",\n",
    "          \"i am working with mitsubishi\"]\n",
    "\n",
    "vocab_list = \" \".join(corups).split()\n",
    "vocab_set = set(vocab_list)\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=vocab_set)\n",
    "\n",
    "x = vectorizer.fit_transform(corups)\n",
    "\n",
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ai', 'am', 'as', 'data', 'gen', 'i', 'is', 'love', 'mitsubishi',\n",
       "       'new', 'nlp', 'oil', 'science', 'teach', 'with', 'working'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF -IDF (Term Frequency - inverse document frequency)\n",
    "\n",
    "#### TF-IDF is a statistical measure used in Natural Language Processing (NLP) to evaluate the importance of a word in a document relative to a collection (corpus) of documents. It helps reduce the weight of common words while highlighting unique words in a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.25417303, 0.        , 0.        , 0.96715876,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.90453403, 0.        , 0.        , 0.        , 0.30151134,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.30151134, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.32238625, 0.64477251, 0.        ,\n",
       "        0.32238625, 0.25417303, 0.        , 0.32238625, 0.        ,\n",
       "        0.32238625, 0.32238625, 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.5       , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.5       , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5       , 0.5       ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfvector = TfidfVectorizer()\n",
    "\n",
    "x = tfvector.fit_transform(corups)\n",
    "\n",
    "x.toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
